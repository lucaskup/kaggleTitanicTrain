{"cells":[{"source":["# First Notebook for Kaggle Competition\n","\n","This notebook achieves a score of 0.78449 in the April competition (the first place got 0.81). It far from the best but was fun to participate in the competition.\n","\n","TLDR: The data file is read, we preprocess the data and input nan values using the mean, one-hot encode the categorical features and use an ensemble of LDA, Random Forest, kNN, SVM, and MLP classifiers."],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Import Libraries\n","from sklearn.neighbors import VALID_METRICS\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.compose import ColumnTransformer\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn import svm\n","from sklearn.neural_network import MLPClassifier\n","\n","\n","from sklearn.neighbors import DistanceMetric\n","\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import GridSearchCV\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  \n","0      0         A/5 21171   7.2500   NaN        S  \n","1      0          PC 17599  71.2833   C85        C  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  \n","3      0            113803  53.1000  C123        S  \n","4      0            373450   8.0500   NaN        S  "],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":2}],"source":["# Read the datasets\n","\n","datasetTrain = pd.read_csv('data/train.csv')\n","datasetTest = pd.read_csv('data/test.csv')\n","datasetTrain.head()\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Defines the function that preprocess the data\n","\n","\n","def preprocessData(df: pd.DataFrame,\n","                   columnTransformer: ColumnTransformer = None,\n","                   complementarySetForNull: pd.DataFrame = None) -> (np.ndarray, np.ndarray, ColumnTransformer):\n","    '''\n","    Preprocess the data passed in, fill None values, encodes categorical features.\n","\n","    Parameters:\n","        df (DataFrame): A pandas dataframe that contains the data to be preprocessed\n","        columnTransformer (ColumnTransformer): optional column transformer to be used if null it creates a new ct\n","        complementarySetForNull (Dataframe): An optional df (test) that is used for inputation of missing values.\n","\n","    Returns:\n","        X (Numpy Array): The feature array already preprocessed\n","        Y (Numpy Array): The target value\n","        ct (Column Transformer): The column transformer used in the preprocess \n","    '''\n","    df.drop(labels=['Name', 'Ticket'],\n","            axis=1,\n","            inplace=True)\n","    if complementarySetForNull is not None:\n","        # Age fillna with mean age\n","        completeDF = pd.concat(\n","            [df, complementarySetForNull]).reset_index(drop=True)\n","        meanAge = completeDF['Age'].mean()\n","        meanFare = completeDF['Fare'].mean()\n","        completeDF = None\n","\n","        df['Age'] = df['Age'].fillna(meanAge)\n","        complementarySetForNull['Age'] = complementarySetForNull['Age'].fillna(\n","            meanAge)\n","\n","        df['Fare'] = df['Fare'].fillna(meanFare)\n","        complementarySetForNull['Fare'] = complementarySetForNull['Fare'].fillna(\n","            meanFare)\n","    df = df.assign(AgeGroup=df['Age'].apply(\n","        lambda x: x // 10 if x // 10 <= 6 else 6))\n","    df = df.assign(hasFamily=(df['SibSp'] + df['Parch']).apply(\n","        lambda x: 1 if x > 0 else 0))\n","    df = df.assign(familySize=(df['SibSp'] + df['Parch']).apply(\n","        lambda x: 0 if pd.isnull(x) else x))\n","    df = df.assign(hasCabin=df['Cabin'].apply(\n","        lambda x: 0 if pd.isnull(x) else 1))\n","    df = df.assign(cabinLetter=df['Cabin'].apply(\n","        lambda x: '.' if pd.isnull(x) else str(x)[0]))\n","    df['Fare'] = df['Fare'].apply(\n","        lambda x: 0 if pd.isnull(x) else x)\n","    df = df.assign(farePerFamily=df['Fare']/(df['familySize']+1))\n","    X = df[['Pclass', 'Sex', 'Fare', 'Embarked',\n","            'AgeGroup', 'hasFamily', 'hasCabin', 'cabinLetter', 'farePerFamily']].values\n","    if 'Survived' in df.columns:\n","        Y = np.ravel(df['Survived'])\n","    else:\n","        Y = None\n","    if columnTransformer is None:\n","        columnTransformer = ColumnTransformer(\n","            [('encoder', OneHotEncoder(drop='first'), [0, 1, 3, 4, 7]),\n","             ('minMaxScaler', MinMaxScaler(), [2, 8])], remainder='passthrough')\n","        X = columnTransformer.fit_transform(X)\n","    else:\n","        X = columnTransformer.transform(X)\n","\n","    return X, Y, columnTransformer\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Preprocess the train and the test set and frees the memory of regarding\n","# the features of the dataset that were not used\n","\n","X, Y, ct = preprocessData(datasetTrain, complementarySetForNull=datasetTest)\n","\n","X_test, _, _ = preprocessData(datasetTest, columnTransformer=ct)\n","passengerIdTest = datasetTest['PassengerId'].values.reshape(-1, 1)\n","\n","datasetTrain = None\n","datasetTest = None\n","ensembleOfModels = []"]},{"source":["# If you don't have enough hardware...\n","Sometimes you just don't have enough hardware available, it was my case in April's competition. My solution was to do a grid search using just a sample of the training set. Usually, you want to use all the data, but if you are on a budget station (like me) a sample can do the job. Use the SAMPLE_RATIO (0,1] below to control how much of the training sample you will use.\n","\n","Feel free to change to 1 if you have enough resources."],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Since we dont have enough hardware to grid search through the entire data\n","# we will take a i.i.d. sample of 10% of our dataset and will use that\n","# to grid search and obtain the best hyperparameters for our models\n","\n","SAMPLE_RATIO = 1\n","sampleIndexes = np.random.choice(len(Y),\n","                                 int(len(Y)*SAMPLE_RATIO),\n","                                 replace=False)\n","X_sample = X[sampleIndexes]\n","Y_sample = Y[sampleIndexes]"]},{"source":["# Grid Search\n","Some models have hyperparameters, aka values that you have to manually set and that are not subject to optimization during the training phase. For those, the best practice is to search through some combination of parameters (trial and error) and select the parameters that create the best model. In sklearn, we have the GridSearchCV that allows us to do a grid search in a k-fold cross-validation setup, we will do that."],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Best Random Forst Classifier:\n   Score > 0.8069288389513108\n   Params > {'criterion': 'entropy', 'n_estimators': 100}\n"]}],"source":["# Grid Search Through the Random Forest Classifier\n","\n","gridParameters = {'n_estimators': [10, 50, 100, 200],\n","                  'criterion': ['gini', 'entropy']}\n","gsCV = GridSearchCV(RandomForestClassifier(),\n","                    gridParameters,\n","                    cv=10,\n","                    n_jobs=-1)\n","\n","gsCV.fit(X_sample, Y_sample)\n","\n","print(\n","    f'Best Random Forst Classifier:\\n   Score > {gsCV.best_score_}\\n   Params > {gsCV.best_params_}')\n","ensembleOfModels.append(gsCV.best_estimator_)\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Best kNN Classifier:\n   Score > 0.7765917602996255\n   Params > {'algorithm': 'auto', 'metric': 'minkowski', 'n_neighbors': 20}\n"]}],"source":["\n","# Grid Search Through the kNN classifier\n","# to use mahalonobis distance we need to pass the keyword parameters\n","# V and VI\n","# in case we want to know the valid distance metrics\n","# we could run => sorted(VALID_METRICS['brute'])\n","\n","covParam = np.cov(X.astype(np.float32))\n","invCovParam = np.linalg.pinv(covParam)\n","\n","gridParameters = [{'algorithm': ['auto'],\n","                  'metric': ['minkowski'],\n","                   'n_neighbors': [5, 10, 20]},\n","                  {'algorithm': ['brute'],\n","                   'metric': ['mahalanobis'],\n","                   'n_neighbors': [5, 10, 20],\n","                   'metric_params': [{'V': covParam,\n","                                      'VI': invCovParam}]}]\n","gsCV = GridSearchCV(KNeighborsClassifier(),\n","                    gridParameters,\n","                    cv=10,\n","                    n_jobs=-1)\n","\n","gsCV.fit(X_sample, Y_sample)\n","\n","print(\n","    f'Best kNN Classifier:\\n   Score > {gsCV.best_score_}\\n   Params > {gsCV.best_params_}')\n","ensembleOfModels.append(gsCV.best_estimator_)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.7957178526841449\n"]}],"source":["# The LDA models does not have much hyperparameters to tune\n","\n","model = LinearDiscriminantAnalysis()\n","cv = cross_validate(model, X_sample, Y_sample, scoring='accuracy', cv=10)\n","\n","print(np.mean(cv['test_score']))\n","\n","ensembleOfModels.append(model)\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Best SVM:\n   Score > 0.8203995006242198\n   Params > {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n"]}],"source":["# Lets grid search through the SVM classifier\n","\n","gridParameters = {'C': [0.1, 1, 10, 100, 1000],\n","                  'gamma': ['auto'],  # [1, 0.1, 0.01, 0.001, 0.0001],\n","                  'kernel': ['rbf']}\n","gsCV = GridSearchCV(svm.SVC(),\n","                    gridParameters,\n","                    cv=10,\n","                    n_jobs=-1)\n","\n","gsCV.fit(X_sample, Y_sample)\n","\n","print(\n","    f'Best SVM:\\n   Score > {gsCV.best_score_}\\n   Params > {gsCV.best_params_}')\n","ensembleOfModels.append(gsCV.best_estimator_)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Best MLP:\n   Score > 0.8113982521847689\n   Params > {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15, 15), 'learning_rate': 'adaptive', 'solver': 'adam'}\n"]}],"source":["# Lets grid search through the MLP classifier\n","\n","gridParameters = {'hidden_layer_sizes': [(5, 5), (10, 5), (10, 10), (15, 10), (15, 15)],\n","                  'activation': ['logistic', 'relu'],\n","                  'solver': ['adam'],\n","                  'alpha': [0.0001, 0.05, 0.005],\n","                  'learning_rate': ['constant', 'adaptive'],\n","                  }\n","gsCV = GridSearchCV(MLPClassifier(max_iter=2500),\n","                    gridParameters,\n","                    cv=10,\n","                    n_jobs=-1)\n","\n","gsCV.fit(X_sample, Y_sample)\n","\n","print(\n","    f'Best MLP:\\n   Score > {gsCV.best_score_}\\n   Params > {gsCV.best_params_}')\n","ensembleOfModels.append(gsCV.best_estimator_)\n"]},{"source":["# The prediction...\n","We now take the best model for each of the five algorithms we used (LDA, kNN, Random Forest, SVM) and we train them with selected hyperparameters using the whole training set.\n","\n","We use each of the five classifiers to predict the target variable. If three or more classifiers vote on a specific outcome that is the outcome of our ensemble classifier."],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Prepare data for Kaggle Submission\n","ensembleOfModels = list(map(lambda m: m.fit(X, Y), ensembleOfModels))\n","\n","\n","predictions = list(map(lambda m: m.predict(X_test), ensembleOfModels))\n","\n","predictionsEnsemble = predictions[0] + predictions[1] + \\\n","    predictions[2] + predictions[3] + predictions[4]\n","# predictionsEnsemble = predictionsEnsemble.apply(lambda x: 1 if x >= 3 else 0)\n","dataForSubmission = pd.DataFrame(np.concatenate((passengerIdTest,\n","                                                 predictionsEnsemble.reshape(-1, 1)), axis=1), columns=['PassengerId', 'Survived'])\n","dataForSubmission['Survived'] = dataForSubmission['Survived'].apply(\n","    lambda x: 1 if x >= 3 else 0)\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   PassengerId  Survived\n","0          892         0\n","1          893         0\n","2          894         0\n","3          895         0\n","4          896         0"],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":13}],"source":["# Creates the submission file\n","dataForSubmission.to_csv('submission/TabularTitanic.csv',\n","                         sep=',',\n","                         decimal='.',\n","                         index=False)\n","dataForSubmission.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"orig_nbformat":2,"kernelspec":{"name":"python3710jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f","display_name":"Python 3.7.10 64-bit ('base': conda)"}}}